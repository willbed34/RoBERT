{"cells":[{"cell_type":"markdown","metadata":{"id":"xsfTMU-dP1Lb"},"source":["TOPIC: RobustBERT/RobustGPT (One of our teams will do GPT the other will do BERT)\n","PROMPT: SENTIMENT CLASSIFICATION\n","\n","Workflow:\n","\n","1. Gather natural language data (depending on prompt)\n","2. Preprocess data (spacy, pytorch, huggingface, Tokenizer)\n","3. Implement models GPT/BERT and train against the collected data\n","4. Create algorithms for adversarial attacks against BERT/GPT (creating typos in words, using wrong synonyms, removing/adding random words, etc)\n","5. Create defenses against the attacks (maybe a second model for cleaning inputs/algorithm to correct typos/etc)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":10731,"status":"ok","timestamp":1701913486387,"user":{"displayName":"Ian Gurland","userId":"09278287982377998029"},"user_tz":300},"id":"DybuayPtP2uu","outputId":"14088c02-05e4-472a-d708-d5671daaf497"},"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.35.2)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.13.1)\n","Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.19.4)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.23.5)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.2)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.1)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2023.6.3)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.31.0)\n","Requirement already satisfied: tokenizers<0.19,>=0.14 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.15.0)\n","Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.1)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.1)\n","Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->transformers) (2023.6.0)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->transformers) (4.5.0)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.6)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.7)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2023.11.17)\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"output_type":"stream","name":"stdout","text":["Input Sentence: I love using this product! It's amazing.\n","Predicted Sentiment Label: 0\n","Predicted Sentiment Probabilities: [[0.6430952548980713, 0.3569047152996063]]\n"]}],"source":["!pip install transformers\n","\n","import torch\n","from transformers import BertTokenizer, BertForSequenceClassification\n","from torch.nn.functional import softmax\n","\n","# Load pre-trained BERT model and tokenizer\n","model_name = 'bert-base-uncased'  # You can use other pre-trained models as well\n","tokenizer = BertTokenizer.from_pretrained(model_name)\n","bertmodel = BertForSequenceClassification.from_pretrained(model_name)\n","\n","# Define a sample sentence for sentiment analysis\n","sentence = \"I love using this product! It's amazing.\"\n","\n","# Tokenize the input sentence and convert to tensor\n","inputs = tokenizer(sentence, return_tensors=\"pt\")\n","input_ids = inputs[\"input_ids\"]\n","\n","# Forward pass through the model\n","outputs = bertmodel(**inputs)\n","\n","# Get the predicted probabilities for each class\n","logits = outputs.logits\n","probs = softmax(logits, dim=1)\n","\n","# Get the predicted sentiment label\n","predicted_label = torch.argmax(probs).item()\n","\n","# Print results\n","print(f\"Input Sentence: {sentence}\")\n","print(f\"Predicted Sentiment Label: {predicted_label}\")\n","print(f\"Predicted Sentiment Probabilities: {probs.tolist()}\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ebRTQ_NxyfUi"},"outputs":[],"source":["import torch\n","from torch.utils.data import DataLoader, Dataset\n","from tqdm import tqdm\n","\n","class SentimentDataset(Dataset):\n","    def __init__(self, texts, labels, tokenizer, max_length=128):\n","        self.texts = texts\n","        self.labels = labels\n","        self.tokenizer = tokenizer\n","        self.max_length = max_length\n","\n","    def __len__(self):\n","        return len(self.texts)\n","\n","    def __getitem__(self, idx):\n","        text = str(self.texts[idx])\n","        label = int(self.labels[idx])\n","        encoding = self.tokenizer(text, truncation=True, padding='max_length', max_length=self.max_length, return_tensors='pt')\n","\n","        return {\n","            'input_ids': encoding['input_ids'].flatten(),\n","            'attention_mask': encoding['attention_mask'].flatten(),\n","            'label': torch.tensor(label, dtype=torch.long)\n","        }"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1053,"status":"ok","timestamp":1701913487413,"user":{"displayName":"Ian Gurland","userId":"09278287982377998029"},"user_tz":300},"id":"4Q7eZK6UzJbf","outputId":"b6cea7d0-2f76-4064-c309-14fbf5a423a3"},"outputs":[{"output_type":"stream","name":"stdout","text":["The autoreload extension is already loaded. To reload it, use:\n","  %reload_ext autoreload\n","Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n","/content/gdrive/Shareddrives/RoBERT\n","lightning_logs\tlogs  preprocess.py  __pycache__  RoBERT  Robert2  RobustGPT  TweetSentiment.csv\n"]}],"source":["%load_ext autoreload\n","%autoreload 2\n","#mount\n","from google.colab import drive\n","drive.mount('/content/gdrive')\n","%cd /content/gdrive/Shareddrives/RoBERT\n","!ls"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"aoxkDzwczqgR"},"outputs":[],"source":["import preprocess\n","tweets, labels = preprocess.get_csv_data(r\"TweetSentiment.csv\")\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":71},"executionInfo":{"elapsed":1586,"status":"ok","timestamp":1701913450928,"user":{"displayName":"Ian Gurland","userId":"09278287982377998029"},"user_tz":300},"id":"OUqnWsOI53Hs","outputId":"49332403-4a2b-41e1-da33-d3bfd672a438"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["'#combine into one list\\ndata = list(zip(tweets, labels))\\nseed = 7\\ntest_percent = 0.2\\ntrain_data, test_data = train_test_split(data, test_size=test_percent, random_state=seed)\\n\\nprint(\"Size of train: \", len(train_data))\\nprint(\"Size of test: \", len(test_data))\\nfor i in range(10, 15):\\n    print(\"This sentence is \", preprocess.number_to_label(test_data[i][1]),\": \",test_data[i][0])'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":5}],"source":["#combine into one list\n","from sklearn.model_selection import train_test_split\n","'''#combine into one list\n","data = list(zip(tweets, labels))\n","seed = 7\n","test_percent = 0.2\n","train_data, test_data = train_test_split(data, test_size=test_percent, random_state=seed)\n","\n","print(\"Size of train: \", len(train_data))\n","print(\"Size of test: \", len(test_data))\n","for i in range(10, 15):\n","    print(\"This sentence is \", preprocess.number_to_label(test_data[i][1]),\": \",test_data[i][0])'''"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"TtVe1aILIuxq"},"outputs":[],"source":["import numpy as np\n","\n","# Split your data into training and testing sets\n","\n","num_examples = 20000\n","\n","texts = np.array(tweets) # List of input texts\n","labels = np.array(labels)  # List of corresponding labels (0 or 1 for binary sentiment classification)\n","\n","train_texts, temp_text, train_labels, temp_labels = train_test_split(texts, labels, test_size=0.01, random_state=42)\n","\n","val_texts, test_texts, val_labels, test_labels = train_test_split(temp_text, temp_labels, test_size=0.5, random_state=42)\n","\n","# Create data loaders\n","train_dataset = SentimentDataset(train_texts, train_labels, tokenizer)\n","val_dataset = SentimentDataset(val_texts, val_labels, tokenizer)\n","test_dataset = SentimentDataset(test_texts, test_labels, tokenizer)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":15307,"status":"ok","timestamp":1701913473262,"user":{"displayName":"Ian Gurland","userId":"09278287982377998029"},"user_tz":300},"id":"-h-j8X_JOEqq","outputId":"94b377de-29b7-4be2-9e80-19ff4ef58b40"},"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.1.0+cu118)\n","Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (0.16.0+cu118)\n","Collecting pytorch-lightning\n","  Downloading pytorch_lightning-2.1.2-py3-none-any.whl (776 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m776.9/776.9 kB\u001b[0m \u001b[31m6.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.35.2)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.13.1)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch) (4.5.0)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch) (1.12)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.2.1)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.2)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2023.6.0)\n","Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch) (2.1.0)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchvision) (1.23.5)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torchvision) (2.31.0)\n","Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision) (9.4.0)\n","Requirement already satisfied: tqdm>=4.57.0 in /usr/local/lib/python3.10/dist-packages (from pytorch-lightning) (4.66.1)\n","Requirement already satisfied: PyYAML>=5.4 in /usr/local/lib/python3.10/dist-packages (from pytorch-lightning) (6.0.1)\n","Collecting torchmetrics>=0.7.0 (from pytorch-lightning)\n","  Downloading torchmetrics-1.2.1-py3-none-any.whl (806 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m806.1/806.1 kB\u001b[0m \u001b[31m14.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from pytorch-lightning) (23.2)\n","Collecting lightning-utilities>=0.8.0 (from pytorch-lightning)\n","  Downloading lightning_utilities-0.10.0-py3-none-any.whl (24 kB)\n","Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.19.4)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2023.6.3)\n","Requirement already satisfied: tokenizers<0.19,>=0.14 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.15.0)\n","Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.1)\n","Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.10/dist-packages (from fsspec->torch) (3.9.1)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from lightning-utilities>=0.8.0->pytorch-lightning) (67.7.2)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (2.1.3)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision) (3.6)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision) (2.0.7)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision) (2023.11.17)\n","Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch) (1.3.0)\n","Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec->torch) (23.1.0)\n","Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec->torch) (6.0.4)\n","Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec->torch) (1.9.3)\n","Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec->torch) (1.4.0)\n","Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec->torch) (1.3.1)\n","Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec->torch) (4.0.3)\n","Installing collected packages: lightning-utilities, torchmetrics, pytorch-lightning\n","Successfully installed lightning-utilities-0.10.0 pytorch-lightning-2.1.2 torchmetrics-1.2.1\n"]}],"source":["pip install torch torchvision pytorch-lightning transformers"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Bxxx8a0kOVSb"},"outputs":[],"source":["import pytorch_lightning as pl\n","from torch.utils.data import RandomSampler\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"TIfLH1swL-U1"},"outputs":[],"source":["import torch.nn.functional as F\n","class BertClassifier(pl.LightningModule):\n","    def __init__(self, num_classes):\n","        super(BertClassifier, self).__init__()\n","        self.bert = bertmodel\n","        self.valoutputs = []\n","\n","    def forward(self, input_ids, attention_mask):\n","        outputs = self.bert(input_ids, attention_mask=attention_mask, output_hidden_states=True)\n","        return outputs\n","\n","    def training_step(self, batch, batch_idx):\n","        input_ids = batch['input_ids']\n","        attention_mask = batch['attention_mask']\n","        labels2 = batch['label']\n","\n","        outputs = self.bert(input_ids, attention_mask).logits\n","        loss = F.cross_entropy(outputs, labels2)\n","\n","        return loss\n","\n","    def validation_step(self, batch, batch_idx):\n","        input_ids = batch['input_ids']\n","        attention_mask = batch['attention_mask']\n","        labels2 = batch['label']\n","\n","        logits2 = self.bert(input_ids, attention_mask).logits\n","\n","        # Use F.cross_entropy for the CrossEntropyLoss\n","        loss = F.cross_entropy(logits2, labels2)\n","\n","        preds = torch.argmax(logits2, dim=1)\n","        accuracy = (preds == labels2).float().mean()\n","``\n","        self.valoutputs.append(accuracy)\n","\n","        return loss\n","\n","    def on_validation_epoch_end(self):\n","        all_preds = torch.stack(self.valoutputs)\n","        avg_val_accuracy = all_preds.mean()\n","        print(f'Validation Accuracy: {avg_val_accuracy.item()}')\n","        self.valoutputs.clear()\n","\n","    def configure_optimizers(self):\n","        optimizer = torch.optim.AdamW(self.parameters(), lr=2e-5)\n","        return optimizer"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"sBxlDdJHMQDv"},"outputs":[],"source":["class RoBERTDataModule(pl.LightningDataModule):\n","    def __init__(self, train_dataset, val_dataset, test_dataset, batch_size):\n","        super(RoBERTDataModule, self).__init__()\n","        self.train_dataset = train_dataset\n","        self.val_dataset = val_dataset\n","        self.test_dataset = test_dataset\n","        self.batch_size = batch_size\n","\n","    def train_dataloader(self):\n","        train_data = DataLoader(self.train_dataset, sampler = RandomSampler(self.train_dataset, num_samples=num_examples), batch_size = self.batch_size)\n","        return train_data\n","\n","    def val_dataloader(self):\n","        val_data = DataLoader(self.val_dataset, batch_size = self.batch_size)\n","        return val_data\n","\n","    def test_dataloader(self):\n","        test_data = DataLoader(self.test_dataset, batch_size = self.batch_size)\n","        return test_data"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":408,"referenced_widgets":["580e16188bd548a6bb7cb598a30eeaec","97a7b73f056d46f197040772bf224e67","f28cc55884eb404f993b91b8da12a1a5","e49ef0c0b10c4a12b572cfba914c28ba","5026f82ba64446f5b2b74b244be55c1c","e3cd971e6f2e4a45a81f76dd0a0be66b","cc73d0e6486c4207829e07b2a77733f9","2b155d98d03a4ba3ad11ef8970626a4d","55470bd5f21046d99854659bc9a27e7d","f6639a114ab44d63b2d02150b2460764","86be3c8f865e44aca6422d3cc95b9722","fb8197f6e0164ce5afcb25682c660630","7f744163c99649049eb5586977d5d34f","37ba9ba3d1c649d88b3d7270f763b4be","f69515a0ade643ad9b2c9d780658bd42","5db699e613b24f80b759cb30e0ff5b58","2664e61d16d545618d4a4fada8fbcde8","e0fcb84ac875452fb920472e3f885cce","a26fcba1f1c04d59b5e1df49415d74a6","b20abd78730f4683a785870d043631ed","50a93e1395a44b69b54ee25e57a38c85","1e481115bc764f23a175f95f0f9c1503","89f820d31eaa4fb48147160e911e71cb","94fbf6712def42d0adb35de9af49d9dd","88d45ab1f2014f24a803fb79dae22c09","acc0d18368144e4f8a0be21d7003e5b6","9bc2d32b07ac4983b53da59bf1ed0c86","a7fa432dee1c4bdc96b6e9ee447a12a6","66b22ada4689400d8f4dd54b18827eaa","ea113820bafe4b9784b36343c40375a2","92bd38324ddf4306a67fa4f4ec5f6db8","0ad56ecb768b43319afe20ea9baebfa2","5136d0cdaa194c33ba5be0e33875a1f3"]},"executionInfo":{"elapsed":525436,"status":"ok","timestamp":1701914012846,"user":{"displayName":"Ian Gurland","userId":"09278287982377998029"},"user_tz":300},"id":"hh_TfGNJQoVf","outputId":"a624e1ee-811e-455f-b660-d06ab7ba3c6b"},"outputs":[{"output_type":"stream","name":"stderr","text":["INFO:pytorch_lightning.utilities.rank_zero:GPU available: True (cuda), used: True\n","INFO:pytorch_lightning.utilities.rank_zero:TPU available: False, using: 0 TPU cores\n","INFO:pytorch_lightning.utilities.rank_zero:IPU available: False, using: 0 IPUs\n","INFO:pytorch_lightning.utilities.rank_zero:HPU available: False, using: 0 HPUs\n","INFO:pytorch_lightning.accelerators.cuda:LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n","INFO:pytorch_lightning.callbacks.model_summary:\n","  | Name | Type                          | Params\n","-------------------------------------------------------\n","0 | bert | BertForSequenceClassification | 109 M \n","-------------------------------------------------------\n","109 M     Trainable params\n","0         Non-trainable params\n","109 M     Total params\n","437.935   Total estimated model params size (MB)\n"]},{"output_type":"display_data","data":{"text/plain":["Sanity Checking: |          | 0/? [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"580e16188bd548a6bb7cb598a30eeaec"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/pytorch_lightning/trainer/connectors/data_connector.py:441: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=1` in the `DataLoader` to improve performance.\n"]},{"output_type":"stream","name":"stdout","text":["Validation Accuracy: 0.53125\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/pytorch_lightning/trainer/connectors/data_connector.py:441: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=1` in the `DataLoader` to improve performance.\n"]},{"output_type":"display_data","data":{"text/plain":["Training: |          | 0/? [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"fb8197f6e0164ce5afcb25682c660630"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Validation: |          | 0/? [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"89f820d31eaa4fb48147160e911e71cb"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Validation Accuracy: 0.8271250128746033\n"]},{"output_type":"stream","name":"stderr","text":["INFO:pytorch_lightning.utilities.rank_zero:`Trainer.fit` stopped: `max_epochs=1` reached.\n"]}],"source":["from torch.utils.data import DataLoader\n","from transformers import AdamW\n","from tqdm import tqdm\n","\n","#train_data and test_data are from prev cell,\n","#stored as [(sentence, sentiment), ...]\n","\n","#HYPERPARAMS\n","NUM_EPOCHS = 1\n","NUM_CLASSES = 2\n","BATCH_SIZE = 16 #batch size\n","#learning_rate = 1e-5\n","\n","model = BertClassifier(num_classes=NUM_CLASSES)\n","data_module = RoBERTDataModule(train_dataset, val_dataset, test_dataset, batch_size=BATCH_SIZE)\n","\n","trainer = pl.Trainer(accelerator='gpu',\n","                     devices=1,\n","                     max_epochs = NUM_EPOCHS,\n","                     min_epochs = NUM_EPOCHS) # Adjust parameters as needed\n","\n","trainer.fit(model, data_module)\n","\n","# Convert dataset to PyTorch DataLoader\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"9QfYxN70Pmld"},"outputs":[],"source":["def classify(sentence):\n","  # Tokenize the input sentence and convert to tensor\n","  inputs = tokenizer(sentence, return_tensors=\"pt\")\n","\n","  input_ids = inputs[\"input_ids\"]\n","  attention_mask = (input_ids != tokenizer.pad_token_id).float()\n","\n","  # Forward pass through the model\n","  outputs = model(input_ids, attention_mask)\n","\n","  # Get the predicted probabilities for each class\n","  logits = outputs.logits\n","  probs = softmax(logits, dim=1)\n","\n","  # Get the predicted sentiment label\n","  predicted_label = torch.argmax(probs).item()\n","\n","  print(preprocess.number_to_label(predicted_label))"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1801,"status":"ok","timestamp":1701914014644,"user":{"displayName":"Ian Gurland","userId":"09278287982377998029"},"user_tz":300},"id":"V9g-dGb1yaWM","outputId":"0bbaf748-4d0f-48ab-9159-a7ea1aa740b6"},"outputs":[{"output_type":"stream","name":"stdout","text":["Positive\n"]}],"source":["classify(\"im going to check twitter\")"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":17,"status":"ok","timestamp":1701914014644,"user":{"displayName":"Ian Gurland","userId":"09278287982377998029"},"user_tz":300},"id":"5Gj7h_bUWezS","outputId":"dc7d438a-dc4c-4bba-eea9-45b741273ab3"},"outputs":[{"output_type":"stream","name":"stdout","text":["Negative\n"]}],"source":["classify(\"I am black\")"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":13,"status":"ok","timestamp":1701914014644,"user":{"displayName":"Ian Gurland","userId":"09278287982377998029"},"user_tz":300},"id":"ybua6TH4yZ7v","outputId":"0d36b789-cbe9-4eb9-d0f9-c06b176ac052"},"outputs":[{"output_type":"stream","name":"stdout","text":["Negative\n"]}],"source":["classify(\"I am white\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Q2646yK1Akfe"},"outputs":[],"source":["# Define a dictionary mapping each key on the keyboard to its nearby keys\n","keyboard_mapping = {\n","        'q': 'qwaserzx',\n","        'w': 'wqesadrfx',\n","        'e': 'ewrsfdctg',\n","        'r': 'retdfgvyh',\n","        't': 'tryughvb',\n","        'y': 'ytughvcxb',\n","        'u': 'uyihjbn',\n","        'i': 'iuojkbnm',\n","        'o': 'oiplkbn',\n","        'p': 'opklmn',\n","        'a': 'aqszx',\n","        's': 'swxadf',\n","        'd': 'desxcfvr',\n","        'f': 'fdgrvct',\n","        'g': 'gfhbtyv',\n","        'h': 'hbgjyunt',\n","        'j': 'jhknuim',\n","        'k': 'kjlinom',\n","        'l': 'lkjmnop',\n","        'z': 'zaxs',\n","        'x': 'xzsdc',\n","        'c': 'cxvdf',\n","        'v': 'vcbfg',\n","        'b': 'bnvgh',\n","        'n': 'nmbhj',\n","        'm': 'mnjkl'\n","    }"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"bTqk11BJXgCu"},"outputs":[],"source":["import random\n","\n","def introduce_typos(sentence, typo_probability):\n","\n","    # Convert the sentence to a list of characters\n","    sentence_chars = list(sentence)\n","\n","    # Iterate through each character and introduce typos with the specified probability\n","    for i in range(len(sentence_chars)):\n","        if random.random() < typo_probability:\n","            # Introduce a typo by selecting a nearby key\n","            current_char = sentence_chars[i].lower()\n","            if current_char in keyboard_mapping:\n","                replacement_char = random.choice(keyboard_mapping[current_char])\n","                sentence_chars[i] = replacement_char\n","\n","    # Convert the list of characters back to a string\n","    return ''.join(sentence_chars)\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":8,"status":"ok","timestamp":1701914014645,"user":{"displayName":"Ian Gurland","userId":"09278287982377998029"},"user_tz":300},"id":"CGwxVJx9AyWU","outputId":"90955fe6-82ea-4b8f-f6b3-9c19e75c836f"},"outputs":[{"output_type":"stream","name":"stdout","text":["Original Sentence: I love BERT.\n","Sentence with Typos: j oove ggRT.\n"]}],"source":["original_sentence = \"I love BERT.\"\n","typo_probability = 0.2  # Adjust the probability as needed\n","sentence_with_typos = introduce_typos(original_sentence, typo_probability)\n","\n","print(\"Original Sentence:\", original_sentence)\n","print(\"Sentence with Typos:\", sentence_with_typos)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":600,"status":"ok","timestamp":1701914015239,"user":{"displayName":"Ian Gurland","userId":"09278287982377998029"},"user_tz":300},"id":"vac1aUL5EKBF","outputId":"b5bf5b78-ac52-44d2-ec6d-01fa6f032570"},"outputs":[{"output_type":"stream","name":"stdout","text":["Positive\n","Negative\n"]}],"source":["original_sentence = \"I'm hot interested in deep learning\"\n","sentence_with_typos = \"I'm not interested in deep learning\"\n","classify(original_sentence)\n","classify(sentence_with_typos)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":268},"executionInfo":{"elapsed":13,"status":"error","timestamp":1701914015240,"user":{"displayName":"Ian Gurland","userId":"09278287982377998029"},"user_tz":300},"id":"5gyddOBkGZvU","outputId":"a173e4fe-c58c-4827-a150-02769e9c15b5"},"outputs":[{"output_type":"stream","name":"stdout","text":["100\n"]},{"output_type":"error","ename":"NameError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-23-dfa341406212>\u001b[0m in \u001b[0;36m<cell line: 13>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0mnum_correct_original\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0mnum_correct_perturbed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnumber_samples\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m   \u001b[0mtrue_label\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msample_labels\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m   \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"og: \"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moriginal_samples\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'number_samples' is not defined"]}],"source":["num_samples = 100\n","original_samples = test_texts[:num_samples]\n","print(len(original_samples))\n","perturbed_samples = []\n","for original_sample in original_samples:\n","  perturbed_sample = introduce_typos(original_sample, 0.2)\n","  perturbed_samples.append(perturbed_sample)\n","\n","sample_labels = test_texts[:num_samples]\n","\n","num_correct_original = 0\n","num_correct_perturbed = 0\n","for i in range(number_samples):\n","  true_label = sample_labels[i]\n","  print(\"og: \", original_samples[i])\n","  predicted_original = classify(original_samples[i])\n","  predicted_perturbed = classify(perturbed_samples[i])\n","  if predicted_original == true_label:\n","    num_correct_original += 1\n","  if predicted_perturbed == true_label:\n","    num_correct_perturbed += 1\n","print(\"Original accuracy: \", num_correct_original / num_samples)\n","print(\"Perturbed accuracy: \", num_correct_perturbed / num_samples)\n"]},{"cell_type":"code","source":[],"metadata":{"id":"GUbykpNjlE4p"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"sAgW-vCG9RsW"},"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"etMINqhHdnVL"},"outputs":[],"source":["# code to generate attacks using PGD\n","# Load pre-trained BERT model and tokenizer\n","# Set model to evaluation mode\n","\n","from sklearn.metrics.pairwise import cosine_similarity\n","\n","bertmodel.eval()\n","\n","def get_nearest_input_ids(embeddings, tokenizer):\n","    # Get the vocabulary embeddings\n","    vocab_embeddings = bertmodel.bert.embeddings.word_embeddings.weight.data\n","\n","    # Calculate cosine similarity between input embeddings and vocabulary embeddings\n","\n","    emb = embeddings.detach().numpy().squeeze()\n","    vem = vocab_embeddings.detach().numpy()\n","\n","    similarities = torch.tensor(cosine_similarity(emb, vem))\n","\n","    # Get the indices of the top-k nearest neighbors for each embedding\n","    most_similar_indices = torch.argmax(similarities, dim=1)\n","\n","    # Convert indices to input IDs\n","\n","    return most_similar_indices\n","\n","def generate_adversarial_example(sentence, label, alpha=1, epsilon=0.12, max_iter=20):\n","    # Tokenize the input sentence\n","    inputs = tokenizer(sentence, return_tensors=\"pt\")#, truncation=True, padding=True)\n","    input_ids = inputs[\"input_ids\"]\n","\n","    print(\"Original Text:\", sentence)\n","\n","    attention_mask = (input_ids != tokenizer.pad_token_id).float()\n","\n","    # Forward pass to get logits\n","\n","    input_embeddings = bertmodel.bert.embeddings.word_embeddings(input_ids).clone().detach().requires_grad_(True)\n","\n","    # Calculate loss (assuming binary classification, adjust as needed)\n","\n","    for i in range(max_iter):\n","\n","        # Forward pass\n","        outputs = bertmodel(inputs_embeds=input_embeddings, attention_mask=attention_mask)\n","        loss = F.cross_entropy(outputs.logits, torch.tensor([label]))\n","\n","        # Backward pass to compute gradients\n","        model.zero_grad()\n","        loss.backward()\n","\n","        # Project the perturbation to stay within the epsilon budget\n","        input_embeddings_grad = input_embeddings.grad.data\n","\n","        input_embeddings = (input_embeddings + alpha * torch.clamp(input_embeddings_grad, -epsilon, epsilon)).clone().detach().requires_grad_(True)\n","\n","        # Clear gradients for the next iteration\n","\n","        # The final input_embeddings contain the perturbed input\n","        perturbed_input_ids = get_nearest_input_ids(input_embeddings, tokenizer)\n","        perturbed_text = tokenizer.decode(perturbed_input_ids.tolist()[1:][:-1])\n","        print(\"Perturbed Text \" + str(i) + \":\", perturbed_text)\n","\n","# Example usage\n","sentence = \"im going on a date with my AI girlfriend.\"\n","label = 1  # Assuming binary classification, adjust as needed\n","\n","perturbed_tokens = generate_adversarial_example(sentence, label)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"D2GoSv9PdqJz"},"outputs":[],"source":[]}],"metadata":{"accelerator":"GPU","colab":{"provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"},"widgets":{"application/vnd.jupyter.widget-state+json":{"580e16188bd548a6bb7cb598a30eeaec":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_97a7b73f056d46f197040772bf224e67","IPY_MODEL_f28cc55884eb404f993b91b8da12a1a5","IPY_MODEL_e49ef0c0b10c4a12b572cfba914c28ba"],"layout":"IPY_MODEL_5026f82ba64446f5b2b74b244be55c1c"}},"97a7b73f056d46f197040772bf224e67":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_e3cd971e6f2e4a45a81f76dd0a0be66b","placeholder":"​","style":"IPY_MODEL_cc73d0e6486c4207829e07b2a77733f9","value":"Sanity Checking DataLoader 0: 100%"}},"f28cc55884eb404f993b91b8da12a1a5":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"","description":"","description_tooltip":null,"layout":"IPY_MODEL_2b155d98d03a4ba3ad11ef8970626a4d","max":2,"min":0,"orientation":"horizontal","style":"IPY_MODEL_55470bd5f21046d99854659bc9a27e7d","value":2}},"e49ef0c0b10c4a12b572cfba914c28ba":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_f6639a114ab44d63b2d02150b2460764","placeholder":"​","style":"IPY_MODEL_86be3c8f865e44aca6422d3cc95b9722","value":" 2/2 [00:00&lt;00:00,  2.61it/s]"}},"5026f82ba64446f5b2b74b244be55c1c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":"inline-flex","flex":null,"flex_flow":"row wrap","grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":"hidden","width":"100%"}},"e3cd971e6f2e4a45a81f76dd0a0be66b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"cc73d0e6486c4207829e07b2a77733f9":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"2b155d98d03a4ba3ad11ef8970626a4d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":"2","flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"55470bd5f21046d99854659bc9a27e7d":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"f6639a114ab44d63b2d02150b2460764":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"86be3c8f865e44aca6422d3cc95b9722":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"fb8197f6e0164ce5afcb25682c660630":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_7f744163c99649049eb5586977d5d34f","IPY_MODEL_37ba9ba3d1c649d88b3d7270f763b4be","IPY_MODEL_f69515a0ade643ad9b2c9d780658bd42"],"layout":"IPY_MODEL_5db699e613b24f80b759cb30e0ff5b58"}},"7f744163c99649049eb5586977d5d34f":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_2664e61d16d545618d4a4fada8fbcde8","placeholder":"​","style":"IPY_MODEL_e0fcb84ac875452fb920472e3f885cce","value":"Epoch 0: 100%"}},"37ba9ba3d1c649d88b3d7270f763b4be":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_a26fcba1f1c04d59b5e1df49415d74a6","max":1250,"min":0,"orientation":"horizontal","style":"IPY_MODEL_b20abd78730f4683a785870d043631ed","value":1250}},"f69515a0ade643ad9b2c9d780658bd42":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_50a93e1395a44b69b54ee25e57a38c85","placeholder":"​","style":"IPY_MODEL_1e481115bc764f23a175f95f0f9c1503","value":" 1250/1250 [08:36&lt;00:00,  2.42it/s, v_num=45]"}},"5db699e613b24f80b759cb30e0ff5b58":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":"inline-flex","flex":null,"flex_flow":"row wrap","grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":"100%"}},"2664e61d16d545618d4a4fada8fbcde8":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e0fcb84ac875452fb920472e3f885cce":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"a26fcba1f1c04d59b5e1df49415d74a6":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":"2","flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b20abd78730f4683a785870d043631ed":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"50a93e1395a44b69b54ee25e57a38c85":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1e481115bc764f23a175f95f0f9c1503":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"89f820d31eaa4fb48147160e911e71cb":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_94fbf6712def42d0adb35de9af49d9dd","IPY_MODEL_88d45ab1f2014f24a803fb79dae22c09","IPY_MODEL_acc0d18368144e4f8a0be21d7003e5b6"],"layout":"IPY_MODEL_9bc2d32b07ac4983b53da59bf1ed0c86"}},"94fbf6712def42d0adb35de9af49d9dd":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_a7fa432dee1c4bdc96b6e9ee447a12a6","placeholder":"​","style":"IPY_MODEL_66b22ada4689400d8f4dd54b18827eaa","value":"Validation DataLoader 0: 100%"}},"88d45ab1f2014f24a803fb79dae22c09":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"","description":"","description_tooltip":null,"layout":"IPY_MODEL_ea113820bafe4b9784b36343c40375a2","max":500,"min":0,"orientation":"horizontal","style":"IPY_MODEL_92bd38324ddf4306a67fa4f4ec5f6db8","value":500}},"acc0d18368144e4f8a0be21d7003e5b6":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_0ad56ecb768b43319afe20ea9baebfa2","placeholder":"​","style":"IPY_MODEL_5136d0cdaa194c33ba5be0e33875a1f3","value":" 500/500 [01:04&lt;00:00,  7.77it/s]"}},"9bc2d32b07ac4983b53da59bf1ed0c86":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":"inline-flex","flex":null,"flex_flow":"row wrap","grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":"hidden","width":"100%"}},"a7fa432dee1c4bdc96b6e9ee447a12a6":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"66b22ada4689400d8f4dd54b18827eaa":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"ea113820bafe4b9784b36343c40375a2":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":"2","flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"92bd38324ddf4306a67fa4f4ec5f6db8":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"0ad56ecb768b43319afe20ea9baebfa2":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5136d0cdaa194c33ba5be0e33875a1f3":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"nbformat":4,"nbformat_minor":0}